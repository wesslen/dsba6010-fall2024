---
sidebar_position: 9
title: Week 12 - LLMs in Production
---

# LLMs in Production

**Objective**: Learn best practices for deploying LLMs in production environments. Students will understand the challenges and solutions for running LLMs at scale.

## Required Readings
- [The Shift from Models to Compound AI Systems](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)
- [Optimizing Latency](https://hamel.dev/notes/llm/inference/03_inference.html)
- [A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)

## Optional Reading

- [Every Way To Get Structured Output From LLMs](https://www.boundaryml.com/blog/structured-output-from-llms)
- [Berkeley Function-Calling Leaderboard](https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html)
