---
sidebar_position: 8
title: Case Study 8 - LLMs in Production
---

# LLMs in Production

**Date**: November 7 ([Class 12](../classes/week12.md))

**Presenters**: LLMOps Developers

## Required Readings

- [The Shift from Models to Compound AI Systems](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/)
- [Optimizing Latency](https://hamel.dev/notes/llm/inference/03_inference.html)
- [A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)

## Optional Reading

- [Every Way To Get Structured Output From LLMs](https://www.boundaryml.com/blog/structured-output-from-llms)
- [Berkeley Function-Calling Leaderboard](https://gorilla.cs.berkeley.edu/blogs/8_berkeley_function_calling_leaderboard.html)
